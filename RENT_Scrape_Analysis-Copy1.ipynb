{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VoCuY0hhMoz5"
   },
   "source": [
    "# Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1NNNvH7TMjQj"
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import pandas as pd\n",
    "import time\n",
    "import urllib.request\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rent Cost Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 987
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 382,
     "status": "error",
     "timestamp": 1532048982854,
     "user": {
      "displayName": "Leifur Sigurdsson",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111769075670530589535"
     },
     "user_tz": 420
    },
    "id": "_6T50OgtQb_G",
    "outputId": "ba0f60ba-2a44-42cf-c083-491d47d2a506"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page is ready\n"
     ]
    }
   ],
   "source": [
    "class CraigslistRENTScraper(object):\n",
    "    def __init__(self, location, bedrooms, sqft, radius, pagenum):\n",
    "# What information I'm scrapping\n",
    "        self.location = location\n",
    "        self.bedrooms = bedrooms\n",
    "        self.sqft = sqft\n",
    "        self.radius = radius\n",
    "        self.pagenum = pagenum\n",
    "        self.num_pages_to_scrape = 25\n",
    "        \n",
    "        self.url = f\"https://{location}.craigslist.org/search/apa?availabilityMode=0&minSqft={sqft}&min_bedrooms={bedrooms}&{pagenum}search_distance={radius}\"\n",
    "\n",
    "#         for i in range(0, 24):\n",
    "#                 if i == 0:\n",
    "#                     self.url = f\"https://{location}.craigslist.org/search/apa?availabilityMode=0&minSqft={sqft}&min_bedrooms={bedrooms}&search_distance={radius}\"\n",
    "#                     print(\"First iteration\")\n",
    "#                     time.sleep(30)\n",
    "#                 else:\n",
    "#                     self.url = f\"https://{location}.craigslist.org/search/apa?availabilityMode=0&minSqft={sqft}&min_bedrooms={bedrooms}&s=\" + str(i * 120) + \"&search_distance={radius}\"\n",
    "#                     print(\"s=\" + str(i * 120))\n",
    "#                     time.sleep(2)\n",
    "        self.driver = webdriver.Firefox()\n",
    "        self.delay = 3\n",
    "\n",
    "\n",
    "# Launch URL and confirm it fully loaded    \n",
    "    def load_craigslist_url(self):\n",
    "        self.driver.get(self.url)\n",
    "        try:\n",
    "            wait = WebDriverWait(self.driver, self.delay)\n",
    "            wait.until(EC.presence_of_element_located((By.ID, \"searchform\")))\n",
    "            print(\"Page is ready\")\n",
    "\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(\"Loading took to much time\")\n",
    "\n",
    "\n",
    "# Build lists of information   \n",
    "    def extract_post_information(self):\n",
    "        all_posts = self.driver.find_elements_by_class_name(\"result-row\")\n",
    "        prices = []\n",
    "        titles = []\n",
    "        dates = []\n",
    "        addresss = []\n",
    "        bedrooms = []\n",
    "        sqfts = []\n",
    "\n",
    "# Clean and divide the post into important sections    \n",
    "        for post in all_posts:\n",
    "#             print(post.text)\n",
    "            title = post.text.split(\"$\")\n",
    "\n",
    "            if title[0] == '':\n",
    "                title = title[1]\n",
    "            else:\n",
    "                title = title[0]\n",
    "\n",
    "            info = post.text.split(\" - \")\n",
    "            address = info[-1]\n",
    "            address = address.strip(\"()\")\n",
    "\n",
    "            bedroom = post.text\n",
    "            pattern = r\"\\s\\d*[b][r]\\s\"\n",
    "            bedroom = (re.findall(pattern,bedroom)[0])\n",
    "\n",
    "            sqft = post.text\n",
    "            sqftpat = r\"\\s\\d*[f][t][2]\"\n",
    "            sqft = (re.findall(sqftpat,sqft)[0])\n",
    "\n",
    "            title = title.split(\"\\n\")\n",
    "            price = title[0]\n",
    "            title = title[-1]\n",
    "\n",
    "            title = title.split(\" \")\n",
    "\n",
    "            month = title[0]\n",
    "            day = title[1]\n",
    "            title = ' '.join(title[2:])\n",
    "            date = month + \" \" + day\n",
    "            \n",
    "# Add to Lists        \n",
    "            prices.append(price)\n",
    "            titles.append(title)\n",
    "            dates.append(date)\n",
    "            addresss.append(address)\n",
    "            bedrooms.append(bedroom)\n",
    "            sqfts.append(sqft)\n",
    "\n",
    "        return prices, titles, dates, addresss, bedrooms, sqfts\n",
    "\n",
    "# Collect post urls and build list    \n",
    "    def extract_post_urls(self):\n",
    "        url_list = []\n",
    "        html_page = urllib.request.urlopen(self.url)\n",
    "        soup = BeautifulSoup(html_page, \"lxml\")\n",
    "        for link in soup.findAll(\"a\", {\"class\": \"result-title hdrlnk\"}):\n",
    "            url_list.append(link[\"href\"])\n",
    "        return url_list\n",
    "        \n",
    "# Close FireFox Browser        \n",
    "    def quit(self):\n",
    "        self.driver.close()\n",
    "    \n",
    "# Specifications for scrape  \n",
    "    \n",
    "location = \"portland\"\n",
    "bedrooms = \"1\"\n",
    "sqft = \"1\"\n",
    "radius = \"100\"\n",
    "pagenum = \"\"\n",
    "\n",
    "scraper = CraigslistRENTScraper(location, bedrooms, sqft, radius, pagenum)\n",
    "scraper.load_craigslist_url()\n",
    "prices, titles, dates, addresss, bedrooms, sqfts = scraper.extract_post_information()\n",
    "url_list = scraper.extract_post_urls()\n",
    "scraper.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1393,
     "status": "ok",
     "timestamp": 1532039591145,
     "user": {
      "displayName": "Leifur Sigurdsson",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111769075670530589535"
     },
     "user_tz": 420
    },
    "id": "YlQwnAxLXoyQ",
    "outputId": "9bcbaf15-43a4-4ca6-dd31-8362c7366c46"
   },
   "outputs": [],
   "source": [
    "rentdf = pd.DataFrame(\n",
    "    {'Price': prices,\n",
    "     'Date': dates,\n",
    "     'Bedrooms': bedrooms,\n",
    "     'SqFt': sqfts,\n",
    "     'Location': addresss,\n",
    "     'Post': titles,\n",
    "     'Url': url_list,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rentdf[\"rooms\"] = rentdf[\"Bedrooms\"].str[:2]\n",
    "rentdf[\"SQFT\"] = rentdf[\"SqFt\"].str[:-3]\n",
    "# rentdf[\"Location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Post</th>\n",
       "      <th>Price</th>\n",
       "      <th>SqFt</th>\n",
       "      <th>Url</th>\n",
       "      <th>rooms</th>\n",
       "      <th>SQFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1br</td>\n",
       "      <td>Jul 24</td>\n",
       "      <td>Sherwood</td>\n",
       "      <td>Quartz Counter Tops! Amazing Renovated 2BD 2BA...</td>\n",
       "      <td>1609</td>\n",
       "      <td>1026ft2</td>\n",
       "      <td>https://portland.craigslist.org/wsc/apa/d/quar...</td>\n",
       "      <td>1</td>\n",
       "      <td>1026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1br</td>\n",
       "      <td>Jul 24</td>\n",
       "      <td>Kerns</td>\n",
       "      <td>Looking For A Place To Call Home In August, Li...</td>\n",
       "      <td>1399</td>\n",
       "      <td>504ft2</td>\n",
       "      <td>https://portland.craigslist.org/mlt/apa/d/look...</td>\n",
       "      <td>1</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1br</td>\n",
       "      <td>Jul 24</td>\n",
       "      <td>clark/cowlitz</td>\n",
       "      <td>Lease Today, Swimming Pool, Gated Community, P...</td>\n",
       "      <td>1354</td>\n",
       "      <td>747ft2</td>\n",
       "      <td>https://portland.craigslist.org/clk/apa/d/leas...</td>\n",
       "      <td>1</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1br</td>\n",
       "      <td>Jul 24</td>\n",
       "      <td>East Gresham</td>\n",
       "      <td>Rare, 1 Bedroom Loft Layout; w/Attached Garage...</td>\n",
       "      <td>1135</td>\n",
       "      <td>670ft2</td>\n",
       "      <td>https://portland.craigslist.org/mlt/apa/d/rare...</td>\n",
       "      <td>1</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2br</td>\n",
       "      <td>Jul 24</td>\n",
       "      <td>Tualatin</td>\n",
       "      <td>This 2bed/2bath is Perfect for You! Come Take ...</td>\n",
       "      <td>1614</td>\n",
       "      <td>944ft2</td>\n",
       "      <td>https://portland.craigslist.org/clc/apa/d/this...</td>\n",
       "      <td>2</td>\n",
       "      <td>944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Bedrooms    Date       Location  \\\n",
       "0     1br   Jul 24       Sherwood   \n",
       "1     1br   Jul 24          Kerns   \n",
       "2     1br   Jul 24  clark/cowlitz   \n",
       "3     1br   Jul 24   East Gresham   \n",
       "4     2br   Jul 24       Tualatin   \n",
       "\n",
       "                                                Post Price      SqFt  \\\n",
       "0  Quartz Counter Tops! Amazing Renovated 2BD 2BA...  1609   1026ft2   \n",
       "1  Looking For A Place To Call Home In August, Li...  1399    504ft2   \n",
       "2  Lease Today, Swimming Pool, Gated Community, P...  1354    747ft2   \n",
       "3  Rare, 1 Bedroom Loft Layout; w/Attached Garage...  1135    670ft2   \n",
       "4  This 2bed/2bath is Perfect for You! Come Take ...  1614    944ft2   \n",
       "\n",
       "                                                 Url rooms   SQFT  \n",
       "0  https://portland.craigslist.org/wsc/apa/d/quar...     1   1026  \n",
       "1  https://portland.craigslist.org/mlt/apa/d/look...     1    504  \n",
       "2  https://portland.craigslist.org/clk/apa/d/leas...     1    747  \n",
       "3  https://portland.craigslist.org/mlt/apa/d/rare...     1    670  \n",
       "4  https://portland.craigslist.org/clc/apa/d/this...     2    944  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rentdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rentdf[\"Location\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Craigslist Real Estate Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CraigslistHOUSEScraper(object):\n",
    "#     def __init__(self, location, bedrooms, sqft, radius, pagenum):\n",
    "# # What information I'm scrapping\n",
    "#         self.location = location\n",
    "#         self.bedrooms = bedrooms\n",
    "#         self.sqft = sqft\n",
    "#         self.radius = radius\n",
    "#         self.pagenum = pagenum\n",
    "#         self.num_pages_to_scrape = 25\n",
    "        \n",
    "#         self.url = f\"https://{location}.craigslist.org/search/rea?availabilityMode=0&minSqft={sqft}&min_bedrooms={bedrooms}&{pagenum}search_distance={radius}\"\n",
    "\n",
    "# #         for i in range(0, 24):\n",
    "# #                 if i == 0:\n",
    "# #                     self.url = f\"https://{location}.craigslist.org/search/rea?availabilityMode=0&minSqft={sqft}&min_bedrooms={bedrooms}&search_distance={radius}\"\n",
    "# #                     print(\"First iteration\")\n",
    "# #                     time.sleep(30)\n",
    "# #                 else:\n",
    "# #                     self.url = f\"https://{location}.craigslist.org/search/rea?availabilityMode=0&minSqft={sqft}&min_bedrooms={bedrooms}&s=\" + str(i * 120) + \"&search_distance={radius}\"\n",
    "# #                     print(\"s=\" + str(i * 120))\n",
    "# #                     time.sleep(2)\n",
    "#         self.driver = webdriver.Firefox()\n",
    "#         self.delay = 3\n",
    "\n",
    "\n",
    "# # Launch URL and confirm it fully loaded    \n",
    "#     def load_craigslist_url(self):\n",
    "#         self.driver.get(self.url)\n",
    "#         try:\n",
    "#             wait = WebDriverWait(self.driver, self.delay)\n",
    "#             wait.until(EC.presence_of_element_located((By.ID, \"searchform\")))\n",
    "#             print(\"Page is ready\")\n",
    "\n",
    "\n",
    "#         except TimeoutException:\n",
    "#             print(\"Loading took to much time\")\n",
    "\n",
    "\n",
    "# # Build lists of information   \n",
    "#     def extract_post_information(self):\n",
    "#         all_posts = self.driver.find_elements_by_class_name(\"result-row\")\n",
    "#         prices = []\n",
    "#         titles = []\n",
    "#         dates = []\n",
    "#         addresss = []\n",
    "#         bedrooms = []\n",
    "#         sqfts = []\n",
    "\n",
    "# # Clean and divide the post into important sections    \n",
    "#         for post in all_posts:\n",
    "# #             print(post.text)\n",
    "#             title = post.text.split(\"$\")\n",
    "\n",
    "#             if title[0] == '':\n",
    "#                 title = title[1]\n",
    "#             else:\n",
    "#                 title = title[0]\n",
    "\n",
    "#             info = post.text.split(\" - \")\n",
    "#             address = info[-1]\n",
    "#             address = address.strip(\"()\")\n",
    "\n",
    "#             bedroom = post.text\n",
    "#             pattern = r\"\\s\\d*[b][r]\\s\"\n",
    "#             bedroom = (re.findall(pattern,bedroom)[0])\n",
    "\n",
    "#             sqft = post.text\n",
    "#             sqftpat = r\"\\s\\d*[f][t][2]\"\n",
    "#             sqft = (re.findall(sqftpat,sqft)[0])\n",
    "\n",
    "#             title = title.split(\"\\n\")\n",
    "#             price = title[0]\n",
    "#             title = title[-1]\n",
    "\n",
    "#             title = title.split(\" \")\n",
    "\n",
    "#             month = title[0]\n",
    "#             day = title[1]\n",
    "#             title = ' '.join(title[2:])\n",
    "#             date = month + \" \" + day\n",
    "            \n",
    "# # Add to Lists        \n",
    "#             prices.append(price)\n",
    "#             titles.append(title)\n",
    "#             dates.append(date)\n",
    "#             addresss.append(address)\n",
    "#             bedrooms.append(bedroom)\n",
    "#             sqfts.append(sqft)\n",
    "\n",
    "#         return prices, titles, dates, addresss, bedrooms, sqfts\n",
    "\n",
    "\n",
    "\n",
    "# #     ['', '375000\\nJul 20 Mid-Century Modern! N. PDX! ', '375000 3br, - 1471ft2, - (N. Portland)']\n",
    "# # Collect post urls and build list    \n",
    "#     def extract_post_urls(self):\n",
    "#         url_list = []\n",
    "#         html_page = urllib.request.urlopen(self.url)\n",
    "#         soup = BeautifulSoup(html_page, \"lxml\")\n",
    "#         for link in soup.findAll(\"a\", {\"class\": \"result-title hdrlnk\"}):\n",
    "#             print(link[\"href\"])\n",
    "#             url_list.append(link[\"href\"])\n",
    "#         return url_list\n",
    "\n",
    "        \n",
    "# # Close FireFox Browser        \n",
    "#     def quit(self):\n",
    "#         self.driver.close()\n",
    "    \n",
    "# # Specifications for scrape  \n",
    "    \n",
    "# location = \"portland\"\n",
    "# bedrooms = \"1\"\n",
    "# sqft = \"1\"\n",
    "# radius = \"100\"\n",
    "\n",
    "\n",
    "# scraper = CraigslistScraper(location, bedrooms, sqft, radius, pagenum)\n",
    "# scraper.load_craigslist_url()\n",
    "# prices, titles, dates, addresss, bedrooms, sqfts = scraper.extract_post_information()\n",
    "# scraper.extract_post_urls()\n",
    "# scraper.quit()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Real estate Scrape Analysis",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
